{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eede350c",
   "metadata": {},
   "source": [
    "<html>\n",
    "<table width=\"100%\" cellspacing=\"2\" cellpadding=\"2\" border=\"1\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td valign=\"center\" align=\"center\" width=\"45%\"><img src=\"../media/Univ-Utah.jpeg\"><br>\n",
    "</td>\n",
    "    <td valign=\"center\" align=\"center\" width=\"75%\">\n",
    "<h1 align=\"center\"><font size=\"+1\">University of Utah<br>Population Health Sciences<br>Data Science Workshop</font></h1></td>\n",
    "<td valign=\"center\" align=\"center\" width=\"45%\"><img\n",
    "src=\"../media/U_Health_stacked_png_red.png\" alt=\"Utah Health\n",
    "Logo\" width=\"128\" height=\"134\"><br>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<br>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5246b3",
   "metadata": {},
   "source": [
    "# Introduction to SQL\n",
    "Now that we have some background about what databases are and how they're structured, we'll get some hands-on experiencing joining tables and querying data from MIMIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca731a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e0f07e",
   "metadata": {},
   "source": [
    "## Connecting to MIMIC\n",
    "Throughout this class, we'll use the function `connect_to_mimic` to connect to the MIMIC database (imported as part of the `helpers` module). This requires the package `pymysql`, so you may have to install that first. \n",
    "\n",
    "\n",
    "#### TODO\n",
    "In the cells below, install `pymysql` and then run the function to connect to the database. Ask your instructor for the password when prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7f4eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter password for MIMIC2 database········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymysql.connections.Connection at 0x7fde980893a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = connect_to_mimic(\"uu-phs\")\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed649db7",
   "metadata": {},
   "source": [
    "Great, we've connected to MIMIC! Now we're almost ready to pull some data. But first we need to learn some basic SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f3e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9f3d939",
   "metadata": {},
   "source": [
    "## Administrative and demographic data\n",
    "For next couple of notebooks, we'll focus on tables containing **ddministrative and demographic data**. These tables define general information about the patient or their hospitalizations. This includes data elements such as:\n",
    "- Name\n",
    "- Sex\n",
    "- Date of birth\n",
    "- Insurance information\n",
    "- Admit/discharge datetime\n",
    "\n",
    "We'll focus on three tables for now: `admission`, `d_patients`, and `demographic_detail`. Let's start writing some queries in SQL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81fe2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c448d280",
   "metadata": {},
   "source": [
    "## SQL\n",
    "**Structured Query Language (SQL)** is a programming language used to interact with many relational databases. There are many different *flavors* of SQL that vary slightly from one another, but the core logic is typically the same.\n",
    "\n",
    "When we use SQL, we execute a **query** which runs some logic to specifyl, filter, and transform data in the database. It then returns the **result set** to us. In Python, we can use the `pandas` function `read_sql` to connect to a database and execute a query.  `pd.read_sql` takes two required arguments:\n",
    "\n",
    "- `sql`: A string containing a SQL query\n",
    "- `con`: The connection object which allows us to access the database \n",
    "For the second argument, we'll use the `conn` object returned by `connect_to_mimic`. The first argument should be a string containing SQL code.\n",
    "\n",
    "Here is an example of executing a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM admissions\n",
    "WHERE admit_dt <= '3033-07-08 00:00:00'\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8b3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25fbf8d1",
   "metadata": {},
   "source": [
    "## Structure of a SQL query\n",
    "\n",
    "Let's go back through that SQL query. If we were to translate the query to natural language, we might express it as:\n",
    "\n",
    "---\n",
    "**\"Give me the top 10 rows of data from the `admissions` table where the admit datetime was before July 8th, 3033.\"** (Why do you think the dates look so weird?)\n",
    "\n",
    "---\n",
    "\n",
    "This returns a pandas DataFrame with four columns and 10 rows.\n",
    "\n",
    "#### Discussion\n",
    "What columns are returned by this query? What do the columns/values mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e10f9",
   "metadata": {},
   "source": [
    "</br>\n",
    "More generally, here is the structure of a SQL query:\n",
    "\n",
    "--- \n",
    "<html>\n",
    "<font>\n",
    "    <p style=\"font-family:courier\";>SELECT COLUMN NAMES (or *)</p>\n",
    "    <p style=\"font-family:courier\";> FROM TABLE NAME</p>\n",
    "    <p style=\"font-family:courier\";>(optional) JOIN</p>\n",
    "    <p style=\"font-family:courier\";>WHERE (condition)</p>\n",
    "    <p style=\"font-family:courier\";>(optional) ORDER BY ...</p>\n",
    "    <p style=\"font-family:courier\";>(optional) LIMIT N ...</p>\n",
    "</html>\n",
    "---\n",
    "\n",
    "Here is a quick explanation of each clause (we'll go through each in detail later):\n",
    "- `SELECT`: This tells us which columns we want to pull. If we say `SELECT *`, that means `\"SELECT ALL\"`\n",
    "- `FROM`: This specifies which table the data will be in\n",
    "- `JOIN`: This joins two tables together using a common key. If we only need a single table, we can leave this out.\n",
    "- `WHERE`: This allows to filter to where rows where a certain condition is matched\n",
    "- `ORDER BY`: This sorts the rows by a particular column\n",
    "- `LIMIT`: This means we only want the first `N` rows. In this class, we'll typically use this clause so we don't pull excessively large datasets.\n",
    "\n",
    "    \n",
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aeaf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_simple_query_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43583d2",
   "metadata": {},
   "source": [
    "Here is a slightly more complicated query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT a.hadm_id, a.subject_id, a.admit_dt, a.disch_dt, p.sex, p.dob, p.dod, p.hospital_expire_flg\n",
    "FROM d_patients  p\n",
    "    INNER JOIN admissions a\n",
    "        ON p.subject_id = a.subject_id\n",
    "WHERE hospital_expire_flg = 'Y'\n",
    "ORDER BY dod\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86fffc",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e76e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_tables_in_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a1fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_order_by_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebfbdb",
   "metadata": {},
   "source": [
    "## Writing queries\n",
    "Now let's go through the different parts of a SQL query and get some practice writing our own queries.\n",
    "\n",
    "### The essentials\n",
    "\n",
    "There are two components that all of our SQL queries will have:\n",
    "1. **The `SELECT` statement**: Here, we *select* the columns that we want to retrieve from the database. You can either list the specific columns you want separated or commas or just say **\"*\"** to pull all of them\n",
    "2. **The `FROM` statement**: We need to specify what table these columns are coming from. We sometimes give a table name an \"alias\" (often a single letter) to refer to in the query.\n",
    "\n",
    "While it's not always essential, in this class we will also often have:\n",
    "3. **A `LIMIT`** statement**: Limit the number of rows we're pulling so we don't overwhelm the database (or your machine).\n",
    "\n",
    "So a very basic query could just select all (or some) of the rows and all of the columns from a single table. The following query pulls every column from the first 10 rows of **d_patients** while giving the table an alias of `d`:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420843d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM d_patients d\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca0f9e",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Write and execute a query to select just the `hadm_id`, `subject_id`, `admit_dt`, and `disch_dt` from the `admissions` table. Give the table an alias of `a`. Limit to the first 25 rows. Save the result as `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f0f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT hadm_id, ____, admit_dt, disch_dt\n",
    "____ admissions a -- alias; using 'AS a' is optional\n",
    "LIMIT ____;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_result1.test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0083bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4682d49d",
   "metadata": {},
   "source": [
    "## Joining tables\n",
    "In a relational database like MIMIC, different attributes for entities are stored in different tables. These disparate tables can then be joined together in a query using a `join` statement. The column `subject_id`, which is the identifier for a patient, is consistent between these two columns and can be used to join them together:\n",
    "\n",
    "```SQL\n",
    "FROM table1\n",
    "    INNER JOIN table2\n",
    "        ON table1.column = table2.column\n",
    "```\n",
    "\n",
    "*Note*: We'll talk more about the phrase `INNER JOIN` later, as well as other types of joins.\n",
    "\n",
    "#### TODO\n",
    "Join the `demographic_detail` and `d_patients` tables using the `subject_id` column in both as the joining keys. Select all columns and the **top 10** rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583948b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ____    \n",
    "FROM ____ d\n",
    "    INNER JOIN d_patients __\n",
    "        ON d.____ = p.____\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd662026",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc19489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd6547b9",
   "metadata": {},
   "source": [
    "## Filtering results\n",
    "Typically we don't want to return *all* rows from a table. We instead usually filter based on conditions related to the columns of the table. This is where the `WHERE` clause comes in.\n",
    "\n",
    "For example, to get the demographic details for a single patient, we can filter based on the `subject_id` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f70c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM demographic_detail d\n",
    "WHERE subject_id = 78\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0c906",
   "metadata": {},
   "source": [
    "You can also use standard comparators like `!=`, `>`, `>=`, `<`, and `<=`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004b9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1795f534",
   "metadata": {},
   "source": [
    "Run the query below - it returns an error. Scroll to the bottom of the error traceback and read the error description:\n",
    "\n",
    "`\"Column 'subject_id' in where clause is ambiguous\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8ae85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT p.subject_id, p.dob, p.dod, d.admission_type_descr\n",
    "FROM demographic_detail d INNER JOIN\n",
    "    d_patients p\n",
    "        ON d.subject_id = p.subject_id\n",
    "WHERE subject_id = 78\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec19c13",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_error_ambiguous "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85daf362",
   "metadata": {},
   "source": [
    "When more than one table in our query has a column of the same name, we need to specify which table we're referring to. We can specify a column using the notation:\n",
    "\n",
    "`table_name.column_name`\n",
    "\n",
    "or, if we're using aliases::\n",
    "\n",
    "`alias.column_name`\n",
    "\n",
    "`WHERE d.subject_id = 78`\n",
    "\n",
    "or:\n",
    "\n",
    "`WHERE p.subject_id = 78`\n",
    "\n",
    "#### TODO\n",
    "Which of the following changes to the `WHERE` clause would cause our query to run correctly?\n",
    "- **a)** `WHERE d.subject_id = 78`\n",
    "- **b)** `WHERE p.subject_id = 78`\n",
    "- **c)** `WHERE ANY(subject_id) = 78`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_fix_where_ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d208dc",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Based on your answer to the previous quiz, fix the query and rerun it, saving the result as `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b86b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST VALUE\n",
    "test_fixed_where_ambiguity.test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758211d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "548cd273",
   "metadata": {},
   "source": [
    "## Ordering results\n",
    "Finally, we can order the queried data by using the `ORDER BY` clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM d_patients\n",
    "WHERE subject_id IN (56, 78, 37)\n",
    "ORDER BY subject_id;\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17799da",
   "metadata": {},
   "source": [
    "By default, `ORDER BY` sorts values in **ascending** order. But we can switch to **descending** order using the `DESC` keyword:\n",
    "\n",
    "```sql\n",
    "ORDER BY column DESC\n",
    "```\n",
    "\n",
    "#### TODO\n",
    "Change the query above to sort the data by `dob` in *descending* order. Rerun and save as `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8808a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST VALUE\n",
    "test_query_dob_descending.test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20acc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c417941f",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "Sometimes we might want to rename our columns, maybe to make it a name that's easier to understand or that is less ambiguous. We do this the same way we assigned *aliases* to tables:\n",
    "\n",
    "```sql\n",
    "SELECT column1 AS new_name\n",
    "    ,column2 new_name2 -- 'AS' is optional\n",
    "```\n",
    "\n",
    "#### TODO\n",
    "Select the first 10 rows of `d_patients` and rename `dob` to `date_of_birth` and `dod` to `date_of_death`. Save the assignment as `df_patients_renamed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    subject_id\n",
    "    ,sex\n",
    "    ,__ AS ____\n",
    "    ,____\n",
    "    ,hospital_expire_flg\n",
    "FROM d_patients\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_patients_renamed = pd.____(____, conn)\n",
    "df_patients_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST VALUE\n",
    "validate_df_patients_renamed.test(df_patients_renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ee60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bec72d5",
   "metadata": {},
   "source": [
    "## Creating new columns with new values\n",
    "Often, tables don't have the exist data element we want. For example, let's say that we want to study patient age at death. There is no exact column for this in `d_patients`, but we can use `dod` and `dob` to calculate a new column.\n",
    "\n",
    "Just like Python, SQL has certain **functions** that you can add to your queries. One such function is `DATEDIFF` which calculates the number of days between two dates:\n",
    "\n",
    "```sql\n",
    "SELECT DATEDIFF(date1, date2)\n",
    "```\n",
    "\n",
    "We can use that to calculate the number of days between patients' death and birth dates. When we calculate a new column we need to give it a name, so we'll call this one `age_at_death_days`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b14c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    subject_id,\n",
    "    dod,\n",
    "    DATEDIFF(dod, dob) age_at_death_days\n",
    "FROM d_patients p\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1457fb",
   "metadata": {},
   "source": [
    "We can also do basic arithmetic like addition, subtraction, multiplication, and division using operators similar to Python: `+`, `-`, `*`, `/`.\n",
    "\n",
    "#### TODO\n",
    "Make a new version of `df_patients` with all 4,000 rows and a new column called `age_at_death` which is the patient's age when they died *in years*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE HINT\n",
    "hint_age_in_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "    ,____\n",
    "\"\"\"\n",
    "\n",
    "df_patients = pd.read_sql(query, conn)\n",
    "df_patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST VALUE\n",
    "test_age_at_death.test(df_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fd60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da03748f",
   "metadata": {},
   "source": [
    "## Aggregating data\n",
    "So far, everything we've done with SQL has been at the **row-level**. That is, we've written queries that have returned results with a single entity (patient, hospitalization, etc.) per row. Next we'll start looking at how to **aggregate** data in SQL.\n",
    "\n",
    "Some examples of aggregate data we coud compute in MIMIC include:\n",
    "- The number of admissions\n",
    "- The count of patients by sex\n",
    "- The min and max admission date for patients\n",
    "- The mean/min/max/standard deviation of length of stay\n",
    "\n",
    "In `module_2`, we learned how to do many of these calculatins in Python using `pandas`. Aggregating data in SQL is very similar. Each of the calculations described above can be computed using a **SQL function** like `COUNT()`, `MIN()`, or `MAX()`.\n",
    "\n",
    "### Counts\n",
    "One of the most basic aggegations is simply counting the number of rows in a table. We can get this by selecting `COUNT(*)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a60f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(1) AS n\n",
    "FROM admissions\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36663908",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "How would you interpret the result above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c85512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_count_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc4343",
   "metadata": {},
   "source": [
    "Aggregate queries can have other clauses like `WHERE`, `JOIN`, etc., so you can filter and join the data you're counting.\n",
    "\n",
    "#### TODO\n",
    "How many rows in the table `demographic_detail` represent an admission from the emergency room?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d220cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_count_ed_admit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef56f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49d16807",
   "metadata": {},
   "source": [
    "### Mins, Maxes, and Means\n",
    "SQL has functions to calculate extreme values, means, and standard deviations. For example, the query below calculates the earliest/latest dates of birth and death:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d707725",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    MIN(dob) earliest_birth, MAX(dob) latest_birth, MIN(dod) earliest_death, MAX(dod) latest_death\n",
    "FROM d_patients p\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e038fe",
   "metadata": {},
   "source": [
    "We can also pass in transformed values to functions. Earlier we'd seen how to calculate how old a patient was in days or years. Now we can calculate summary statistics like the mean and standard deviation using `AVG()` and `STD()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    AVG(DATEDIFF(dod, dob)) avg_age_at_death_days,\n",
    "    STD(DATEDIFF(dod, dob)) std_age_at_death_days\n",
    "FROM d_patients p\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9160d",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Calculate the min, max, mean, and standard deviation age at death *in years*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_summary_stats_age_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ad7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    ____ min_age_at_death,\n",
    "    MAX(____) ____,\n",
    "    ____ mean_age_at_death,\n",
    "    ____ sd_age_at_death\n",
    "FROM d_patients p\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e694a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cd5891e",
   "metadata": {},
   "source": [
    "### GROUP BY\n",
    "The queries above gave us single aggregate stats over an entire set of patients. But we might want to break our statistics up into groups. We'll use the `GROUP BY` clause for that. \n",
    "\n",
    "The `GROUP BY` clause tells us which column to use for breaking our patients up into groups. This works just like `df.groupby` in pandas. \n",
    "\n",
    "The query below counts the number of patients by `sex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT sex, COUNT(1) n\n",
    "FROM d_patients \n",
    "GROUP BY sex\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b211cb8",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Count the number of hospital admissions grouped by `admission_source_descr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ba15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_count_admission_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718005c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fc5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581d1d84",
   "metadata": {},
   "source": [
    "We can also group by multiple columns at once. This query calculates the number of patients in `demographic_detail` grouped by both sex and race and sorts in descending order of count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44148621",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    d.ethnicity_descr, \n",
    "    p.sex,\n",
    "    COUNT(*) n\n",
    "FROM d_patients p\n",
    "    INNER JOIN demographic_detail d\n",
    "        ON p.subject_id = d.subject_id\n",
    "GROUP BY d.ethnicity_descr, p.sex\n",
    "ORDER BY COUNT(*) desc\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4433845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "689f8feb",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Write a query to count how many patients died in the hospital grouped by `sex`. Then answer the quiz below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE HINT\n",
    "hint_count_hospital_expire_by_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_count_hospital_expire_by_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e07ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559be12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
